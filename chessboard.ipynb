# Install necessary packages
!pip install opencv-python numpy matplotlib

# Import libraries
import cv2
import numpy as np
import matplotlib.pyplot as plt
from google.colab import files

# Upload images
uploaded_files = files.upload()
image_dict = {}
for file_name in uploaded_files:
    image = cv2.imread(file_name)
    if image is not None:
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image_dict[file_name] = image_rgb

def check_skew(pts, angle_threshold=10, ratio_tolerance=0.2):
    """
    Checks if the detected quadrilateral is skewed based on internal angles and aspect ratio.
    Returns True if correction might be needed.
    """
    rect = arrange_points(pts)
    (tl, tr, br, bl) = rect

    def calculate_angle(v1, v2):
        norm_v1 = np.linalg.norm(v1)
        norm_v2 = np.linalg.norm(v2)

        if norm_v1 == 0 or norm_v2 == 0:
            return 0

        unit_v1 = v1 / norm_v1
        unit_v2 = v2 / norm_v2

        dot_product = np.clip(np.dot(unit_v1, unit_v2), -1.0, 1.0)
        angle_in_radians = np.arccos(dot_product)

        return np.degrees(angle_in_radians)

    angles = [
        calculate_angle(tr - tl, bl - tl),
        calculate_angle(bl - tl, br - bl),
        calculate_angle(br - bl, tr - br),
        calculate_angle(tr - br, tr - tl)
    ]

    if all(abs(90 - angle) < angle_threshold for angle in angles):
        width_top = np.linalg.norm(tr - tl)
        height_left = np.linalg.norm(bl - tl)
        ratio = width_top / height_left if height_left != 0 else 0

        if 1 - ratio_tolerance < ratio < 1 + ratio_tolerance:
            return False

    return True

def arrange_points(pts):
    """
    Reorders a set of 4 corner points consistently: [top-left, top-right, bottom-right, bottom-left].
    """
    rect = np.zeros((4, 2), dtype="float32")
    sum_pts = pts.sum(axis=1)
    diff_pts = np.diff(pts, axis=1)

    rect[0] = pts[np.argmin(sum_pts)] 
    rect[2] = pts[np.argmax(sum_pts)] 
    rect[1] = pts[np.argmin(diff_pts)] 
    rect[3] = pts[np.argmax(diff_pts)] 
    return rect

def apply_perspective_transform(image, pts):
    """
    Applies perspective transformation to obtain a top-down view of the selected region.
    """
    rect = arrange_points(pts)
    (tl, tr, br, bl) = rect

    width_A = np.linalg.norm(br - bl)
    width_B = np.linalg.norm(tr - tl)
    max_width = max(int(width_A), int(width_B))

    height_A = np.linalg.norm(tr - br)
    height_B = np.linalg.norm(tl - bl)
    max_height = max(int(height_A), int(height_B))

    dst_points = np.array([
        [0, 0],
        [max_width - 1, 0],
        [max_width - 1, max_height - 1],
        [0, max_height - 1]
    ], dtype="float32")

    transformation_matrix = cv2.getPerspectiveTransform(rect, dst_points)
    warped_image = cv2.warpPerspective(image, transformation_matrix, (max_width, max_height))

    return warped_image

def detect_largest_quadrilateral_and_correct(img):
    """
    Finds the largest convex quadrilateral in the image, orders its corners, and applies a perspective warp.
    """
    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    blurred_img = cv2.GaussianBlur(gray_img, (5, 5), 0)
    edges_img = cv2.Canny(blurred_img, 50, 150)

    contours, _ = cv2.findContours(edges_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    max_area = 0
    best_quad = None

    for contour in contours:
        epsilon = 0.05 * cv2.arcLength(contour, True)
        approximated = cv2.approxPolyDP(contour, epsilon, True)
        if len(approximated) == 4 and cv2.isContourConvex(approximated):
            area = cv2.contourArea(approximated)
            if area > max_area:
                max_area = area
                best_quad = approximated

    if best_quad is None:
        print("No suitable quadrilateral found.")
        return img

    pts = best_quad.reshape(4, 2)
    rect = arrange_points(pts)

    return apply_perspective_transform(img, rect)

def prepare_image(image):
    """
    Converts RGB image to grayscale, enhances contrast with CLAHE, and applies adaptive thresholding.
    """
    gray_img = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    blurred_img = cv2.GaussianBlur(gray_img, (5, 5), 0)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced_img = clahe.apply(blurred_img)
    thresholded_img = cv2.adaptiveThreshold(enhanced_img, 255, cv2.ADAPTIVE_THRESH_MEAN_C,
                                            cv2.THRESH_BINARY_INV, 11, 3)
    return gray_img, enhanced_img, thresholded_img

def annotate_chessboard(image, grid_dimensions=(8, 8)):
    """
    Splits the image into a grid, classifies each square, and annotates them on the image.
    """
    annotated_img = image.copy()
    h, w = image.shape[:2]
    cell_height, cell_width = h // grid_dimensions[1], w // grid_dimensions[0]

    gray_img = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    font = cv2.FONT_HERSHEY_SIMPLEX

    black_squares, white_squares = 0, 0

    for row in range(grid_dimensions[1]):
        for col in range(grid_dimensions[0]):
            x_start = col * cell_width
            y_start = row * cell_height
            roi = gray_img[y_start:y_start + cell_height, x_start:x_start + cell_width]
            mean_intensity = np.mean(roi)

            label = "Black" if mean_intensity < 128 else "White"
            color = (0, 255, 0) if label == "Black" else (255, 0, 0)

            if label == "Black":
                black_squares += 1
            else:
                white_squares += 1

            cv2.rectangle(annotated_img,
                          (x_start, y_start),
                          (x_start + cell_width, y_start + cell_height),
                          color, 2)

            cv2.putText(annotated_img,
                        label,
                        (x_start + 5, y_start + 20),
                        font, 0.5,
                        color, 1, cv2.LINE_AA)

    return annotated_img, black_squares, white_squares

def grid_count_chessboard_squares(image, grid_dimensions=(8, 8)):
    """
    Divides the image into a grid and counts the number of dark and light squares based on pixel intensity.
    """
    h, w = image.shape[:2]
    cell_height, cell_width = h // grid_dimensions[1], w // grid_dimensions[0]

    black_squares = 0
    white_squares = 0

    gray_img = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)

    for row in range(grid_dimensions[1]):
        for col in range(grid_dimensions[0]):
            x_start = col * cell_width
            y_start = row * cell_height
            roi = gray_img[y_start:y_start + cell_height, x_start:x_start + cell_width]
            mean_intensity = np.mean(roi)

            if mean_intensity < 128:
                black_squares += 1
            else:
                white_squares += 1

    return black_squares, white_squares

for key in image_dict.keys():
    print(key)
    sample_img = image_dict[key]

    corrected_img = detect_largest_quadrilateral_and_correct(sample_img)

    gray, clahe_enhanced, thresholded = prepare_image(corrected_img)

    plt.figure(figsize=(20, 4))

    plt.subplot(1, 5, 1)
    plt.imshow(sample_img)
    plt.title("Original")
    plt.axis("off")

    plt.subplot(1, 5, 2)
    plt.imshow(corrected_img)
    plt.title("Corrected View")
    plt.axis("off")

    plt.subplot(1, 5, 3)
    plt.imshow(gray, cmap="gray")
    plt.title("Gray")
    plt.axis("off")

    plt.subplot(1, 5, 4)
    plt.imshow(clahe_enhanced, cmap="gray")
    plt.title("Enhanced")
    plt.axis("off")

    plt.subplot(1, 5, 5)
    plt.imshow(thresholded, cmap="gray")
    plt.title("Thresholded")
    plt.axis("off")

    plt.tight_layout()
    plt.show()

    black_count, white_count = grid_count_chessboard_squares(corrected_img)
    print(f"Black Squares: {black_count}")
    print(f"White Squares: {white_count}")

    labeled_img, black_count, white_count = annotate_chessboard(corrected_img)

    plt.figure(figsize=(10, 10))
    plt.imshow(labeled_img)
    plt.title(f"Squares Detected\n Black: {black_count}, White: {white_count}")
    plt.axis('off')
    plt.show()
